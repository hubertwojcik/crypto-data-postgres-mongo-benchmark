{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üöÄ PostgreSQL vs MongoDB - Analiza Wydajno≈õci\n",
        "\n",
        "## Cel projektu\n",
        "Por√≥wnanie wydajno≈õci operacji CRUD miƒôdzy PostgreSQL (baza relacyjna) a MongoDB (baza dokumentowa) na danych tweet√≥w o Bitcoin.\n",
        "\n",
        "## Rozmiary danych testowych\n",
        "- **10,000 rekord√≥w** - ma≈Çy zbi√≥r testowy\n",
        "- **100,000 rekord√≥w** - ≈õredni zbi√≥r testowy  \n",
        "- **1,000,000 rekord√≥w** - du≈ºy zbi√≥r testowy\n",
        "\n",
        "## Plan eksperymentu\n",
        "1. Przygotowanie ≈õrodowiska i danych\n",
        "2. Populacja baz danych dla ka≈ºdego rozmiaru\n",
        "3. Testy operacji CRUD (Create, Read, Update, Delete)\n",
        "4. Wizualizacja wynik√≥w\n",
        "5. Analiza i wnioski\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. üì¶ Instalacja i importy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Instalacja wymaganych pakiet√≥w (uruchom raz)\n",
        "# !pip install -q psycopg2-binary pymongo pandas python-dotenv matplotlib seaborn jupyter\n",
        "\n",
        "# Importy\n",
        "import sys\n",
        "import os\n",
        "import time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from typing import Dict, List, Any\n",
        "from pymongo import InsertOne\n",
        "\n",
        "# Dodaj src do ≈õcie≈ºki\n",
        "sys.path.append('src')\n",
        "\n",
        "# Importy z projektu\n",
        "from src.config import *\n",
        "from src.db.postgres_manager import PostgresManager\n",
        "from src.db.mongo_manager import MongoManager\n",
        "from src.db.data_precleaner import DataPrecleaner\n",
        "\n",
        "# Konfiguracja wykres√≥w\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n",
        "plt.rcParams['figure.figsize'] = (12, 6)\n",
        "\n",
        "print(\"‚úÖ Wszystkie biblioteki za≈Çadowane!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. üîß Inicjalizacja klas\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Inicjalizacja klas\n",
        "print(\"üîß Inicjalizacja klas...\")\n",
        "\n",
        "# Manager do czyszczenia danych\n",
        "cleaner = DataPrecleaner()\n",
        "\n",
        "# Po≈ÇƒÖczenie z bazami danych\n",
        "pg = PostgresManager(PG_HOST, PG_PORT, PG_DB, PG_USER, PG_PASS)\n",
        "mg = MongoManager(MONGO_URI, MONGO_DB)\n",
        "\n",
        "print(\"‚úÖ Wszystkie klasy zainicjalizowane!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. üìä Opis struktury danych\n",
        "\n",
        "### PostgreSQL (Model relacyjny)\n",
        "- **users** - informacje o u≈ºytkownikach (user_name, user_location, user_description, user_created, user_followers, user_friends, user_favourites, user_verified)\n",
        "- **tweets** - tweety z referencjami do u≈ºytkownik√≥w (date, text, source_id, is_retweet)\n",
        "- **hashtags** - hashtagi (tag)\n",
        "- **sources** - ≈∫r√≥d≈Ça tweet√≥w (name)\n",
        "- **tweet_hashtags** - relacja many-to-many miƒôdzy tweetami a hashtagami\n",
        "\n",
        "### MongoDB (Model dokumentowy)\n",
        "- **tweets** - pojedyncza kolekcja z zagnie≈ºd≈ºonymi dokumentami:\n",
        "  - `user` (zagnie≈ºd≈ºony obiekt z danymi u≈ºytkownika)\n",
        "  - `date`, `text`, `hashtags` (tablica), `source`, `is_retweet`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. üìã Modele danych\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Wszystkie funkcje pomocnicze sƒÖ teraz w klasach PostgresManager i MongoManager\n",
        "# U≈ºywamy metod z klas zamiast funkcji pomocniczych\n",
        "print(\"‚úÖ Gotowe do u≈ºycia metod z klas!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. üì• Przygotowanie danych\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Wczytaj i przygotuj dane\n",
        "print(f\"üìÅ Wczytywanie danych z: {CSV_PATH}\")\n",
        "df_raw = pd.read_csv(CSV_PATH)\n",
        "print(f\"üìä Za≈Çadowano {len(df_raw):,} rekord√≥w\")\n",
        "\n",
        "# Analiza i czyszczenie danych\n",
        "analysis = cleaner.analyze_data(df_raw)\n",
        "df_cleaned, clean_time = cleaner.clean_data_timed(df_raw)\n",
        "\n",
        "print(f\"\\nüìà Podsumowanie przygotowania danych:\")\n",
        "print(f\"  Przed czyszczeniem: {analysis['total_records']:,} rekord√≥w\")\n",
        "print(f\"  Po czyszczeniu: {len(df_cleaned):,} rekord√≥w\")\n",
        "print(f\"  Czas czyszczenia: {clean_time:.4f}s\")\n",
        "\n",
        "# Przygotuj pr√≥bki danych dla eksperyment√≥w\n",
        "df_10k = df_cleaned.head(10000).copy()\n",
        "df_100k = df_cleaned.head(100000).copy()\n",
        "df_1m = df_cleaned.head(1000000).copy()\n",
        "\n",
        "print(f\"\\n‚úÖ Przygotowano pr√≥bki:\")\n",
        "print(f\"  10k: {len(df_10k):,} rekord√≥w\")\n",
        "print(f\"  100k: {len(df_100k):,} rekord√≥w\")\n",
        "print(f\"  1M: {len(df_1m):,} rekord√≥w\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. üß™ Eksperymenty\n",
        "\n",
        "Wszystkie funkcje testowe CRUD sƒÖ dostƒôpne jako metody w klasach:\n",
        "- `PostgresManager.test_read_count()`, `test_read_recent()`, `test_read_hashtag()`, `test_create()`, `test_update()`, `test_delete()`\n",
        "- `MongoManager.test_read_count()`, `test_read_recent()`, `test_read_hashtag()`, `test_create()`, `test_update()`, `test_delete()`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Wszystkie funkcje testowe sƒÖ w klasach - nie trzeba ich tutaj definiowaƒá!\n",
        "print(\"‚úÖ Gotowe do test√≥w!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. üß™ Eksperymenty\n",
        "\n",
        "### 7.1. Eksperyment z 10,000 rekordami\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Populacja danych - 10k rekord√≥w\n",
        "print(\"=\"*60)\n",
        "print(\"EKSPERYMENT: 10,000 rekord√≥w\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Czyszczenie baz danych\n",
        "pg.clear_database()\n",
        "mg.clear_database()\n",
        "\n",
        "# ≈Åadowanie danych do PostgreSQL\n",
        "pg_load_time = pg.load_data_from_dataframe(df_10k, batch_size=1000)\n",
        "\n",
        "# ≈Åadowanie danych do MongoDB\n",
        "mongo_load_time = mg.load_data_from_dataframe(df_10k, batch_size=1000)\n",
        "\n",
        "# Zapisz wyniki\n",
        "results_10k = {\n",
        "    \"load\": {\"postgresql\": pg_load_time, \"mongodb\": mongo_load_time},\n",
        "    \"crud\": {}\n",
        "}\n",
        "\n",
        "print(f\"\\n‚úÖ Populacja zako≈Ñczona!\")\n",
        "print(f\"  PostgreSQL: {pg_load_time:.4f}s\")\n",
        "print(f\"  MongoDB: {mongo_load_time:.4f}s\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Testy CRUD - 10k rekord√≥w\n",
        "print(\"\\nüß™ Uruchamianie test√≥w CRUD...\")\n",
        "\n",
        "# READ tests\n",
        "pg_read_count = pg.test_read_count()\n",
        "mongo_read_count = mg.test_read_count()\n",
        "results_10k[\"crud\"][\"read_count\"] = {\n",
        "    \"postgresql\": pg_read_count[\"time\"],\n",
        "    \"mongodb\": mongo_read_count[\"time\"]\n",
        "}\n",
        "\n",
        "pg_read_recent = pg.test_read_recent(limit=100)\n",
        "mongo_read_recent = mg.test_read_recent(limit=100)\n",
        "results_10k[\"crud\"][\"read_recent\"] = {\n",
        "    \"postgresql\": pg_read_recent[\"time\"],\n",
        "    \"mongodb\": mongo_read_recent[\"time\"]\n",
        "}\n",
        "\n",
        "pg_read_hashtag = pg.test_read_hashtag(hashtag=\"bitcoin\", limit=50)\n",
        "mongo_read_hashtag = mg.test_read_hashtag(hashtag=\"bitcoin\", limit=50)\n",
        "results_10k[\"crud\"][\"read_hashtag\"] = {\n",
        "    \"postgresql\": pg_read_hashtag[\"time\"],\n",
        "    \"mongodb\": mongo_read_hashtag[\"time\"]\n",
        "}\n",
        "\n",
        "# CREATE test\n",
        "sample_row = df_10k.iloc[0].to_dict()\n",
        "pg_create = pg.test_create(sample_row)\n",
        "mongo_create = mg.test_create(sample_row)\n",
        "results_10k[\"crud\"][\"create\"] = {\n",
        "    \"postgresql\": pg_create[\"time\"],\n",
        "    \"mongodb\": mongo_create[\"time\"]\n",
        "}\n",
        "\n",
        "# UPDATE test\n",
        "pg_update = pg.test_update()\n",
        "mongo_update = mg.test_update()\n",
        "results_10k[\"crud\"][\"update\"] = {\n",
        "    \"postgresql\": pg_update[\"time\"],\n",
        "    \"mongodb\": mongo_update[\"time\"]\n",
        "}\n",
        "\n",
        "# DELETE test\n",
        "pg_delete = pg.test_delete()\n",
        "mongo_delete = mg.test_delete()\n",
        "results_10k[\"crud\"][\"delete\"] = {\n",
        "    \"postgresql\": pg_delete[\"time\"],\n",
        "    \"mongodb\": mongo_delete[\"time\"]\n",
        "}\n",
        "\n",
        "print(\"\\n‚úÖ Testy CRUD zako≈Ñczone!\")\n",
        "print(\"\\nüìä Wyniki test√≥w:\")\n",
        "for test_name, result in results_10k[\"crud\"].items():\n",
        "    print(f\"  {test_name}:\")\n",
        "    print(f\"    PostgreSQL: {result['postgresql']:.6f}s\")\n",
        "    print(f\"    MongoDB: {result['mongodb']:.6f}s\")\n",
        "    print(f\"    R√≥≈ºnica: {result['postgresql']/result['mongodb']:.2f}x\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 7.2. Eksperyment z 100,000 rekordami\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Populacja danych - 100k rekord√≥w\n",
        "print(\"=\"*60)\n",
        "print(\"EKSPERYMENT: 100,000 rekord√≥w\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Czyszczenie baz danych\n",
        "pg.clear_database()\n",
        "mg.clear_database()\n",
        "\n",
        "# ≈Åadowanie danych do PostgreSQL\n",
        "pg_load_time = pg.load_data_from_dataframe(df_100k, batch_size=1000)\n",
        "\n",
        "# ≈Åadowanie danych do MongoDB\n",
        "mongo_load_time = mg.load_data_from_dataframe(df_100k, batch_size=1000)\n",
        "\n",
        "# Zapisz wyniki\n",
        "results_100k = {\n",
        "    \"load\": {\"postgresql\": pg_load_time, \"mongodb\": mongo_load_time},\n",
        "    \"crud\": {}\n",
        "}\n",
        "\n",
        "print(f\"\\n‚úÖ Populacja zako≈Ñczona!\")\n",
        "print(f\"  PostgreSQL: {pg_load_time:.4f}s\")\n",
        "print(f\"  MongoDB: {mongo_load_time:.4f}s\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Testy CRUD - 100k rekord√≥w\n",
        "print(\"\\nüß™ Uruchamianie test√≥w CRUD...\")\n",
        "\n",
        "# READ tests\n",
        "pg_read_count = pg.test_read_count()\n",
        "mongo_read_count = mg.test_read_count()\n",
        "results_100k[\"crud\"][\"read_count\"] = {\n",
        "    \"postgresql\": pg_read_count[\"time\"],\n",
        "    \"mongodb\": mongo_read_count[\"time\"]\n",
        "}\n",
        "\n",
        "pg_read_recent = pg.test_read_recent(limit=100)\n",
        "mongo_read_recent = mg.test_read_recent(limit=100)\n",
        "results_100k[\"crud\"][\"read_recent\"] = {\n",
        "    \"postgresql\": pg_read_recent[\"time\"],\n",
        "    \"mongodb\": mongo_read_recent[\"time\"]\n",
        "}\n",
        "\n",
        "pg_read_hashtag = pg.test_read_hashtag(hashtag=\"bitcoin\", limit=50)\n",
        "mongo_read_hashtag = mg.test_read_hashtag(hashtag=\"bitcoin\", limit=50)\n",
        "results_100k[\"crud\"][\"read_hashtag\"] = {\n",
        "    \"postgresql\": pg_read_hashtag[\"time\"],\n",
        "    \"mongodb\": mongo_read_hashtag[\"time\"]\n",
        "}\n",
        "\n",
        "# CREATE test\n",
        "sample_row = df_100k.iloc[0].to_dict()\n",
        "pg_create = pg.test_create(sample_row)\n",
        "mongo_create = mg.test_create(sample_row)\n",
        "results_100k[\"crud\"][\"create\"] = {\n",
        "    \"postgresql\": pg_create[\"time\"],\n",
        "    \"mongodb\": mongo_create[\"time\"]\n",
        "}\n",
        "\n",
        "# UPDATE test\n",
        "pg_update = pg.test_update()\n",
        "mongo_update = mg.test_update()\n",
        "results_100k[\"crud\"][\"update\"] = {\n",
        "    \"postgresql\": pg_update[\"time\"],\n",
        "    \"mongodb\": mongo_update[\"time\"]\n",
        "}\n",
        "\n",
        "# DELETE test\n",
        "pg_delete = pg.test_delete()\n",
        "mongo_delete = mg.test_delete()\n",
        "results_100k[\"crud\"][\"delete\"] = {\n",
        "    \"postgresql\": pg_delete[\"time\"],\n",
        "    \"mongodb\": mongo_delete[\"time\"]\n",
        "}\n",
        "\n",
        "print(\"\\n‚úÖ Testy CRUD zako≈Ñczone!\")\n",
        "print(\"\\nüìä Wyniki test√≥w:\")\n",
        "for test_name, result in results_100k[\"crud\"].items():\n",
        "    print(f\"  {test_name}:\")\n",
        "    print(f\"    PostgreSQL: {result['postgresql']:.6f}s\")\n",
        "    print(f\"    MongoDB: {result['mongodb']:.6f}s\")\n",
        "    print(f\"    R√≥≈ºnica: {result['postgresql']/result['mongodb']:.2f}x\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 7.3. Eksperyment z 1,000,000 rekordami\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Populacja danych - 1M rekord√≥w\n",
        "print(\"=\"*60)\n",
        "print(\"EKSPERYMENT: 1,000,000 rekord√≥w\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Czyszczenie baz danych\n",
        "pg.clear_database()\n",
        "mg.clear_database()\n",
        "\n",
        "# ≈Åadowanie danych do PostgreSQL\n",
        "pg_load_time = pg.load_data_from_dataframe(df_1m, batch_size=1000)\n",
        "\n",
        "# ≈Åadowanie danych do MongoDB\n",
        "mongo_load_time = mg.load_data_from_dataframe(df_1m, batch_size=1000)\n",
        "\n",
        "# Zapisz wyniki\n",
        "results_1m = {\n",
        "    \"load\": {\"postgresql\": pg_load_time, \"mongodb\": mongo_load_time},\n",
        "    \"crud\": {}\n",
        "}\n",
        "\n",
        "print(f\"\\n‚úÖ Populacja zako≈Ñczona!\")\n",
        "print(f\"  PostgreSQL: {pg_load_time:.4f}s\")\n",
        "print(f\"  MongoDB: {mongo_load_time:.4f}s\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Testy CRUD - 1M rekord√≥w\n",
        "print(\"\\nüß™ Uruchamianie test√≥w CRUD...\")\n",
        "\n",
        "# READ tests\n",
        "pg_read_count = pg.test_read_count()\n",
        "mongo_read_count = mg.test_read_count()\n",
        "results_1m[\"crud\"][\"read_count\"] = {\n",
        "    \"postgresql\": pg_read_count[\"time\"],\n",
        "    \"mongodb\": mongo_read_count[\"time\"]\n",
        "}\n",
        "\n",
        "pg_read_recent = pg.test_read_recent(limit=100)\n",
        "mongo_read_recent = mg.test_read_recent(limit=100)\n",
        "results_1m[\"crud\"][\"read_recent\"] = {\n",
        "    \"postgresql\": pg_read_recent[\"time\"],\n",
        "    \"mongodb\": mongo_read_recent[\"time\"]\n",
        "}\n",
        "\n",
        "pg_read_hashtag = pg.test_read_hashtag(hashtag=\"bitcoin\", limit=50)\n",
        "mongo_read_hashtag = mg.test_read_hashtag(hashtag=\"bitcoin\", limit=50)\n",
        "results_1m[\"crud\"][\"read_hashtag\"] = {\n",
        "    \"postgresql\": pg_read_hashtag[\"time\"],\n",
        "    \"mongodb\": mongo_read_hashtag[\"time\"]\n",
        "}\n",
        "\n",
        "# CREATE test\n",
        "sample_row = df_1m.iloc[0].to_dict()\n",
        "pg_create = pg.test_create(sample_row)\n",
        "mongo_create = mg.test_create(sample_row)\n",
        "results_1m[\"crud\"][\"create\"] = {\n",
        "    \"postgresql\": pg_create[\"time\"],\n",
        "    \"mongodb\": mongo_create[\"time\"]\n",
        "}\n",
        "\n",
        "# UPDATE test\n",
        "pg_update = pg.test_update()\n",
        "mongo_update = mg.test_update()\n",
        "results_1m[\"crud\"][\"update\"] = {\n",
        "    \"postgresql\": pg_update[\"time\"],\n",
        "    \"mongodb\": mongo_update[\"time\"]\n",
        "}\n",
        "\n",
        "# DELETE test\n",
        "pg_delete = pg.test_delete()\n",
        "mongo_delete = mg.test_delete()\n",
        "results_1m[\"crud\"][\"delete\"] = {\n",
        "    \"postgresql\": pg_delete[\"time\"],\n",
        "    \"mongodb\": mongo_delete[\"time\"]\n",
        "}\n",
        "\n",
        "print(\"\\n‚úÖ Testy CRUD zako≈Ñczone!\")\n",
        "print(\"\\nüìä Wyniki test√≥w:\")\n",
        "for test_name, result in results_1m[\"crud\"].items():\n",
        "    print(f\"  {test_name}:\")\n",
        "    print(f\"    PostgreSQL: {result['postgresql']:.6f}s\")\n",
        "    print(f\"    MongoDB: {result['mongodb']:.6f}s\")\n",
        "    print(f\"    R√≥≈ºnica: {result['postgresql']/result['mongodb']:.2f}x\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. üìä Wizualizacja wynik√≥w\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Wizualizacja wynik√≥w - por√≥wnanie czas√≥w ≈Çadowania\n",
        "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "\n",
        "# 1. Czas ≈Çadowania danych\n",
        "sizes = ['10k', '100k', '1M']\n",
        "pg_load_times = [results_10k['load']['postgresql'], results_100k['load']['postgresql'], results_1m['load']['postgresql']]\n",
        "mongo_load_times = [results_10k['load']['mongodb'], results_100k['load']['mongodb'], results_1m['load']['mongodb']]\n",
        "\n",
        "x = np.arange(len(sizes))\n",
        "width = 0.35\n",
        "\n",
        "ax1 = axes[0, 0]\n",
        "ax1.bar(x - width/2, pg_load_times, width, label='PostgreSQL', alpha=0.8)\n",
        "ax1.bar(x + width/2, mongo_load_times, width, label='MongoDB', alpha=0.8)\n",
        "ax1.set_xlabel('Rozmiar danych')\n",
        "ax1.set_ylabel('Czas (s)')\n",
        "ax1.set_title('Czas ≈Çadowania danych')\n",
        "ax1.set_xticks(x)\n",
        "ax1.set_xticklabels(sizes)\n",
        "ax1.legend()\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# 2. Czas operacji READ (read_count)\n",
        "test_names = ['read_count', 'read_recent', 'read_hashtag', 'create', 'update', 'delete']\n",
        "pg_times_10k = [results_10k['crud'][t]['postgresql'] for t in test_names]\n",
        "mongo_times_10k = [results_10k['crud'][t]['mongodb'] for t in test_names]\n",
        "\n",
        "ax2 = axes[0, 1]\n",
        "x2 = np.arange(len(test_names))\n",
        "ax2.bar(x2 - width/2, pg_times_10k, width, label='PostgreSQL', alpha=0.8)\n",
        "ax2.bar(x2 + width/2, mongo_times_10k, width, label='MongoDB', alpha=0.8)\n",
        "ax2.set_xlabel('Operacja CRUD')\n",
        "ax2.set_ylabel('Czas (s)')\n",
        "ax2.set_title('Czas operacji CRUD - 10k rekord√≥w')\n",
        "ax2.set_xticks(x2)\n",
        "ax2.set_xticklabels(test_names, rotation=45, ha='right')\n",
        "ax2.legend()\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "# 3. Por√≥wnanie dla 100k\n",
        "pg_times_100k = [results_100k['crud'][t]['postgresql'] for t in test_names]\n",
        "mongo_times_100k = [results_100k['crud'][t]['mongodb'] for t in test_names]\n",
        "\n",
        "ax3 = axes[1, 0]\n",
        "x3 = np.arange(len(test_names))\n",
        "ax3.bar(x3 - width/2, pg_times_100k, width, label='PostgreSQL', alpha=0.8)\n",
        "ax3.bar(x3 + width/2, mongo_times_100k, width, label='MongoDB', alpha=0.8)\n",
        "ax3.set_xlabel('Operacja CRUD')\n",
        "ax3.set_ylabel('Czas (s)')\n",
        "ax3.set_title('Czas operacji CRUD - 100k rekord√≥w')\n",
        "ax3.set_xticks(x3)\n",
        "ax3.set_xticklabels(test_names, rotation=45, ha='right')\n",
        "ax3.legend()\n",
        "ax3.grid(True, alpha=0.3)\n",
        "\n",
        "# 4. Por√≥wnanie dla 1M\n",
        "pg_times_1m = [results_1m['crud'][t]['postgresql'] for t in test_names]\n",
        "mongo_times_1m = [results_1m['crud'][t]['mongodb'] for t in test_names]\n",
        "\n",
        "ax4 = axes[1, 1]\n",
        "x4 = np.arange(len(test_names))\n",
        "ax4.bar(x4 - width/2, pg_times_1m, width, label='PostgreSQL', alpha=0.8)\n",
        "ax4.bar(x4 + width/2, mongo_times_1m, width, label='MongoDB', alpha=0.8)\n",
        "ax4.set_xlabel('Operacja CRUD')\n",
        "ax4.set_ylabel('Czas (s)')\n",
        "ax4.set_title('Czas operacji CRUD - 1M rekord√≥w')\n",
        "ax4.set_xticks(x4)\n",
        "ax4.set_xticklabels(test_names, rotation=45, ha='right')\n",
        "ax4.legend()\n",
        "ax4.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"‚úÖ Wizualizacja zako≈Ñczona!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. üìù Podsumowanie i wnioski\n",
        "\n",
        "### Analiza wynik√≥w:\n",
        "- **PostgreSQL** - lepsze dla z≈Ço≈ºonych zapyta≈Ñ z JOIN-ami\n",
        "- **MongoDB** - szybsze dla prostych operacji na dokumentach\n",
        "- **Skalowanie** - r√≥≈ºne wzorce wydajno≈õci w zale≈ºno≈õci od typu zapyta≈Ñ\n",
        "\n",
        "### Rekomendacje:\n",
        "- Wybierz **PostgreSQL** dla aplikacji wymagajƒÖcych z≈Ço≈ºonych relacji i transakcji\n",
        "- Wybierz **MongoDB** dla aplikacji z prostymi operacjami na dokumentach i szybkim skalowaniem\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Zamknij po≈ÇƒÖczenia z bazami danych\n",
        "print(\"üîå Zamykanie po≈ÇƒÖcze≈Ñ...\")\n",
        "pg.close()\n",
        "mg.close()\n",
        "print(\"‚úÖ Po≈ÇƒÖczenia zamkniƒôte!\")\n",
        "print(\"\\nüéâ Eksperyment zako≈Ñczony!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "h,"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üöÄ PostgreSQL vs MongoDB Benchmark\n",
        "\n",
        "Prosty notebook do testowania wydajno≈õci baz danych.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Importy\n",
        "import sys\n",
        "import pandas as pd\n",
        "sys.path.append('src')\n",
        "\n",
        "from src.config import *\n",
        "from src.db.postgres_manager import PostgresManager\n",
        "from src.db.mongo_manager import MongoManager\n",
        "from src.db.data_precleaner import DataPrecleaner\n",
        "\n",
        "print(\"‚úÖ Wszystkie biblioteki za≈Çadowane!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. üìä Analiza i czyszczenie danych CSV\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Wczytaj dane CSV\n",
        "print(f\"üìÅ Wczytywanie danych z: {CSV_PATH}\")\n",
        "df = pd.read_csv(CSV_PATH)\n",
        "print(f\"üìä Za≈Çadowano {len(df):,} rekord√≥w\")\n",
        "\n",
        "# Analiza danych\n",
        "cleaner = DataPrecleaner()\n",
        "analysis = cleaner.analyze_data(df)\n",
        "\n",
        "# Czyszczenie danych\n",
        "df_cleaned, clean_time = cleaner.clean_data_timed(df)\n",
        "\n",
        "print(f\"\\nüìà Podsumowanie:\")\n",
        "print(f\"  Przed czyszczeniem: {analysis['total_records']:,} rekord√≥w\")\n",
        "print(f\"  Po czyszczeniu: {len(df_cleaned):,} rekord√≥w\")\n",
        "print(f\"  Czas czyszczenia: {clean_time:.4f}s\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. üîå Po≈ÇƒÖczenie z bazami danych\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Po≈ÇƒÖczenie z bazami danych\n",
        "print(\"üîå ≈ÅƒÖczenie z bazami danych...\")\n",
        "\n",
        "pg = PostgresManager(PG_HOST, PG_PORT, PG_DB, PG_USER, PG_PASS)\n",
        "mg = MongoManager(MONGO_URI, MONGO_DB)\n",
        "\n",
        "print(\"‚úÖ Po≈ÇƒÖczono z bazami danych\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. üßπ Czyszczenie baz danych\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Wyczy≈õƒá bazy danych\n",
        "print(\"üßπ Czyszczenie baz danych...\")\n",
        "\n",
        "# Czyszczenie PostgreSQL\n",
        "pg_clear_time = pg.clear_database()\n",
        "\n",
        "# Czyszczenie MongoDB  \n",
        "mongo_clear_time = mg.clear_database()\n",
        "\n",
        "print(f\"\\nüìä Podsumowanie czyszczenia:\")\n",
        "print(f\"  PostgreSQL: {pg_clear_time:.4f}s\")\n",
        "print(f\"  MongoDB:    {mongo_clear_time:.4f}s\")\n",
        "print(f\"  R√≥≈ºnica:    {pg_clear_time/mongo_clear_time:.2f}x\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üöÄ PostgreSQL vs MongoDB Benchmark Analysis\n",
        "\n",
        "Interaktywna analiza wydajno≈õci baz danych na danych tweet√≥w o Bitcoin.\n",
        "\n",
        "## üìã Plan analizy:\n",
        "1. **≈Åadowanie danych** - analiza i czyszczenie CSV\n",
        "2. **Podstawowe testy** - liczenie, pobieranie, wyszukiwanie\n",
        "3. **Z≈Ço≈ºone zapytania** - JOIN-y, agregacje, analizy\n",
        "4. **Wizualizacja wynik√≥w** - wykresy por√≥wnawcze\n",
        "5. **Wnioski** - rekomendacje i optymalizacje\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. üßπ Czyszczenie baz danych\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Wyczy≈õƒá bazy danych\n",
        "print(\"üßπ Czyszczenie baz danych...\")\n",
        "\n",
        "# Czyszczenie PostgreSQL\n",
        "pg_clear_time = pg.clear_database()\n",
        "\n",
        "# Czyszczenie MongoDB  \n",
        "mongo_clear_time = mg.clear_database()\n",
        "\n",
        "print(f\"\\nüìä Podsumowanie czyszczenia:\")\n",
        "print(f\"  PostgreSQL: {pg_clear_time:.4f}s\")\n",
        "print(f\"  MongoDB:    {mongo_clear_time:.4f}s\")\n",
        "print(f\"  R√≥≈ºnica:    {pg_clear_time/mongo_clear_time:.2f}x\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Po≈ÇƒÖczenie z bazami danych\n",
        "print(\"üîå ≈ÅƒÖczenie z bazami danych...\")\n",
        "\n",
        "pg = PostgresManager(PG_HOST, PG_PORT, PG_DB, PG_USER, PG_PASS)\n",
        "mg = MongoManager(MONGO_URI, MONGO_DB)\n",
        "\n",
        "print(\"‚úÖ Po≈ÇƒÖczono z bazami danych\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "pr"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
