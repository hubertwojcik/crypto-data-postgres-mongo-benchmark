# ğŸš€ Crypto Data PostgreSQL vs MongoDB Benchmark

Projekt porÃ³wnujÄ…cy wydajnoÅ›Ä‡ PostgreSQL i MongoDB na danych tweetÃ³w o Bitcoin (~22M rekordÃ³w).

## ğŸ“‹ Funkcje

- **ETL Pipeline**: Åadowanie i normalizacja danych z CSV
- **Dual Database**: PostgreSQL (relacyjny) vs MongoDB (dokumentowy)
- **Basic Benchmarking**: Podstawowe testy wydajnoÅ›ci po zaÅ‚adowaniu danych
- **Data Cleaning**: Automatyczne czyszczenie baz przed Å‚adowaniem

## ğŸš€ Szybki start

### 1. Uruchom bazy danych
```bash
docker compose up -d
```

### 2. Zainstaluj zaleÅ¼noÅ›ci
```bash
python -m venv .venv && source .venv/bin/activate   # macOS/Linux
pip install -r requirements.txt
```

### 3. (Opcjonalnie) SprawdÅº poÅ‚Ä…czenia
```bash
python test_setup.py
```

### 4. (Opcjonalnie) Przeanalizuj dane CSV
```bash
python analyze_csv.py
```

### 5. ZaÅ‚aduj dane i uruchom benchmarki
```bash
python -m src.main
```

### 6. (Opcjonalnie) Interaktywne testy w Jupyter

**Opcja A: Jupyter przez Docker (zalecane)**
```bash
# Uruchom wszystkie serwisy
docker compose up -d

# JeÅ›li kontener Jupyter juÅ¼ byÅ‚ uruchomiony PRZED dodaniem zmiennych Å›rodowiskowych,
# musisz go przebudowaÄ‡ (nie wystarczy restart):
docker compose stop jupyter
docker compose rm -f jupyter
docker compose up -d jupyter

# Lub uÅ¼yj skryptu pomocniczego:
./restart_jupyter.sh

# Jupyter Lab bÄ™dzie dostÄ™pny na http://localhost:8888
# OtwÃ³rz benchmark_analysis.ipynb w przeglÄ…darce
```

**Uwaga:** 
- W kontenerze Docker automatycznie uÅ¼ywane sÄ… nazwy serwisÃ³w (`postgres`, `mongo`) zamiast `localhost`
- JeÅ›li widzisz bÅ‚Ä…d poÅ‚Ä…czenia, sprawdÅº komÃ³rkÄ™ "1.5. Sprawdzenie konfiguracji" w notebooku
- JeÅ›li zmienne Å›rodowiskowe pokazujÄ… `localhost` w Dockerze, przebuduj kontener

**Opcja B: Jupyter lokalnie**
```bash
jupyter lab benchmark_analysis.ipynb
# lub
jupyter notebook benchmark_analysis.ipynb
```

To polecenie:
- Przeanalizuje i wyczyÅ›ci dane z CSV
- WyczyÅ›ci obie bazy danych
- ZaÅ‚aduje wyczyszczone dane do obu baz
- Uruchomi podstawowe testy wydajnoÅ›ci

**Jupyter Notebook** pozwala na:
- Interaktywne testowanie funkcji z klas
- WizualizacjÄ™ wynikÃ³w benchmarkÃ³w
- Eksperymentowanie z rÃ³Å¼nymi zapytaniami
- AnalizÄ™ danych krok po kroku

## ğŸ“Š Struktura danych

### PostgreSQL (Model relacyjny)
- `users` - informacje o uÅ¼ytkownikach
- `tweets` - tweety z referencjami do uÅ¼ytkownikÃ³w
- `hashtags` - hashtagi
- `sources` - ÅºrÃ³dÅ‚a tweetÃ³w
- `tweet_hashtags` - relacja many-to-many

### MongoDB (Model dokumentowy)
- `tweets` - pojedyncza kolekcja z zagnieÅ¼dÅ¼onymi dokumentami uÅ¼ytkownikÃ³w

## ğŸ§¹ Czyszczenie danych

Projekt automatycznie czyÅ›ci dane CSV przed Å‚adowaniem:

### Analiza danych
- Sprawdza brakujÄ…ce wartoÅ›ci w kaÅ¼dej kolumnie
- Liczy unikalne wartoÅ›ci
- Pokazuje przykÅ‚adowe dane
- WyÅ›wietla statystyki jakoÅ›ci

### Czyszczenie danych
- **Usuwa duplikaty** - eliminuje powtarzajÄ…ce siÄ™ rekordy
- **CzyÅ›ci kolumny tekstowe** - usuwa puste stringi
- **Waliduje kluczowe pola** - `user_name`, `date`, `text` muszÄ… byÄ‡ wypeÅ‚nione
- **Naprawia wartoÅ›ci numeryczne** - zastÄ™puje ujemne wartoÅ›ci i NaN zerami
- **Normalizuje boolean** - zastÄ™puje NaN wartoÅ›ciami `False`
- **UzupeÅ‚nia ÅºrÃ³dÅ‚a** - zastÄ™puje puste ÅºrÃ³dÅ‚a wartoÅ›ciÄ… "Unknown"

### Walidacja jakoÅ›ci
- Sprawdza unikalnoÅ›Ä‡ `user_name`
- Weryfikuje poprawnoÅ›Ä‡ dat
- Kontroluje wartoÅ›ci numeryczne
- Raportuje znalezione problemy

## ğŸ” Podstawowe testy wydajnoÅ›ci

Po zaÅ‚adowaniu danych automatycznie uruchamiane sÄ…:

### Test 1: Liczenie rekordÃ³w
- PorÃ³wnanie szybkoÅ›ci zliczania tweetÃ³w i uÅ¼ytkownikÃ³w
- PostgreSQL: `COUNT(*)` na tabelach
- MongoDB: `count_documents()` i `distinct()`

### Test 2: Najnowsze tweety
- Pobieranie 100 najnowszych tweetÃ³w z informacjami o uÅ¼ytkownikach
- PostgreSQL: `JOIN` z `ORDER BY` i `LIMIT`
- MongoDB: `find()` z `sort()` i `limit()`

### Test 3: Wyszukiwanie po hashtagach
- Filtrowanie tweetÃ³w zawierajÄ…cych hashtag "bitcoin"
- PostgreSQL: `JOIN` przez tabele `tweet_hashtags` i `hashtags`
- MongoDB: `find()` z filtrem na tablicy `hashtags`

## ğŸ› ï¸ Konfiguracja

Zmienne Å›rodowiskowe (`.env`):
```bash
# PostgreSQL
POSTGRES_USER=user
POSTGRES_PASSWORD=pass
POSTGRES_DB=social

# MongoDB
MONGO_URI=mongodb://localhost:27017
MONGO_DB=social

# ETL
CSV_PATH=data/Bitcoin_tweets.csv
BATCH_SIZE=1000
```

## ğŸ“ Struktura projektu

```
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ config.py          # Konfiguracja
â”‚   â”œâ”€â”€ main.py            # ETL pipeline + podstawowe benchmarki
â”‚   â”œâ”€â”€ db/
â”‚   â”‚   â”œâ”€â”€ postgres_manager.py
â”‚   â”‚   â””â”€â”€ mongo_manager.py
â”‚   â””â”€â”€ etl/
â”‚       â””â”€â”€ load_tweets.py
â”œâ”€â”€ data/
â”‚   â””â”€â”€ Bitcoin_tweets.csv
â”œâ”€â”€ docker-compose.yaml
â””â”€â”€ requirements.txt
```

## ğŸ¯ Cel projektu

PorÃ³wnanie wydajnoÅ›ci dwÃ³ch rÃ³Å¼nych paradygmatÃ³w baz danych:
- **PostgreSQL**: Relacyjny model z normalizacjÄ…, JOIN-y, ACID
- **MongoDB**: Dokumentowy model, zagnieÅ¼dÅ¼one struktury, elastycznoÅ›Ä‡

Na zbiorze danych tweetÃ³w o Bitcoin, testujÄ…c rÃ³Å¼ne scenariusze uÅ¼ycia i wzorce dostÄ™pu do danych.